{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jn6x-VUy2Qm",
        "outputId": "29b98136-3580-449c-8d29-b3edbe2bbb94"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown https://drive.google.com/drive/folders/19JWGJib5Y3PixVbsAf-EpYZZkkFvU6DC?usp=sharing"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLJWpfMZy3bI",
        "outputId": "45cc9d21-23d1-4814-9321-047483d4c657"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gdown/parse_url.py:35: UserWarning: You specified a Google Drive link that is not the correct link to download a file. You might want to try `--fuzzy` option or the following url: https://drive.google.com/uc?id=None\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/drive/folders/19JWGJib5Y3PixVbsAf-EpYZZkkFvU6DC?usp=sharing\n",
            "To: /content/19JWGJib5Y3PixVbsAf-EpYZZkkFvU6DC?usp=sharing\n",
            "1.64kB [00:00, 3.26MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "#os.chdir(\"/content/drive/My Drive/Colab Notebooks/Comp432Project/Dataset1/ColorectalCancer_\")#100\n",
        "os.chdir(\"/content/drive/My Drive/Colab Notebooks/500 Data/Colorectal Cancer\") #500"
      ],
      "metadata": {
        "id": "JzJVnF1ey7st"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "\n",
        "#print(torch.cuda.is_available())\n",
        "\n",
        "#torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "iGY7lPxlA6N3"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_data():\n",
        "    #data_dir = '/content/drive/My Drive/Colab Notebooks/Comp432Project/Dataset1/ColorectalCancer_' #100\n",
        "    data_dir = '/content/drive/My Drive/Colab Notebooks/500 Data/Colorectal Cancer' #500\n",
        "    transform = transforms.Compose([transforms.ToTensor(),transforms.Resize((128,128))])\n",
        "    data_set = datasets.ImageFolder(root=data_dir, transform=transform)\n",
        "    print(data_set.classes)\n",
        "\n",
        "    n = len(data_set)  # total number of examples\n",
        "    n_test = int(0.20 * n)  # take ~20% for test\n",
        "    for x in range(0, 9):  # rounding it to be divisible by 4\n",
        "        n_test += 1\n",
        "        if n_test % 4 == 0:\n",
        "            break\n",
        "    train_set, test_set = torch.utils.data.random_split(data_set, [n - n_test, n_test])\n",
        "\n",
        "    train = DataLoader(train_set, batch_size=32, shuffle=True)\n",
        "    test = DataLoader(test_set, batch_size= 10, shuffle=False)\n",
        "\n",
        "\n",
        "    return train, test\n"
      ],
      "metadata": {
        "id": "JSPM_zWYBAhI"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "YAU1Kv4ExxQN"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Defining the Model\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "\n",
        "        # First convolutional layer (conv1)\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        # Second convolutional layer (conv2)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        # Shortcut connection (if needed)\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_channels != out_channels:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_channels)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        out += self.shortcut(x)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "#\n",
        "class ResNet18(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(ResNet18, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "        self.layer1 = self.make_layer(64, 64, 2, stride=1)\n",
        "        self.layer2 = self.make_layer(64, 128, 2, stride=2)\n",
        "        self.layer3 = self.make_layer(128, 256, 2, stride=2)\n",
        "        self.layer4 = self.make_layer(256, 512, 2, stride=2)\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(512, num_classes)\n",
        "\n",
        "    def make_layer(self, in_channels, out_channels, num_blocks, stride):\n",
        "        layers = []\n",
        "        layers.append(ResidualBlock(in_channels, out_channels, stride))\n",
        "        for _ in range(1, num_blocks):\n",
        "            layers.append(ResidualBlock(out_channels, out_channels, 1))\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        # x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting the data\n",
        "train, test= get_data()\n",
        "# Instanciating the ResNet18 Class created earlier and Assigning it as our model\n",
        "model = ResNet18(3)\n",
        "\n",
        "# The loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "#\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "# momentum=0.9\n",
        "\n",
        "# Using Cuda cores for the training\n",
        "#model=model.cuda()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jVXDuz1vBR5Z",
        "outputId": "96ab6579-a6d4-4d34-b6f5-c95cd3642718"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['MUS', 'NORM', 'STR']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training\n",
        "num_epoch=10\n",
        "num_epoch_saved=0\n",
        "lr=0.01\n",
        "test_size=0\n",
        "\n",
        "\n",
        "train_losses = []\n",
        "train_accuracy = []\n",
        "test_losses = []\n",
        "test_accuracy = []\n",
        "\n",
        "running_train_losses = []\n",
        "running_test_losses = []\n",
        "\n",
        "#For Saving the model\n",
        "#'/content/drive/My Drive/Colab Notebooks/Saved models/Latest save'\n",
        "model_name_to_save = 'model.pth'\n",
        "save_dir=F\"/content/drive/My Drive/Colab Notebooks/Saved models/Latest save/{model_name_to_save}\"\n",
        "\n",
        "\n",
        "print(\"train\")\n",
        "for epoch in range(num_epoch):\n",
        "    model.train()\n",
        "    loss_train= 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    test_size=0\n",
        "\n",
        "    if epoch>=1:\n",
        "      state_dict = torch.load(save_dir)\n",
        "      model.load_state_dict(state_dict)\n",
        "\n",
        "\n",
        "    for inputs, labels in train:\n",
        "      optimizer.zero_grad()\n",
        "      outputs = model(inputs)\n",
        "      loss_train = criterion(outputs, labels)\n",
        "      loss_train.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      #Loss by input Train\n",
        "      loss_by_input=loss_train.item()\n",
        "      loss_train += loss_train.item()\n",
        "      print(f\"Epoch {epoch+1}/{num_epoch}, Loss: {loss_by_input}\")\n",
        "\n",
        "      #Accuracy\n",
        "      total += labels.size(0)\n",
        "      _, predicted = torch.max(outputs.data, 1)\n",
        "      correct += (predicted == labels).sum().item()\n",
        "\n",
        "\n",
        "    # Checking if the loss has improved this epoch. If so it will save that model,\n",
        "    # otherwise it will just reload the previous  model and continue from there.\n",
        "    loss_by_epoch=loss_train / len(train)\n",
        "    print(\"This epoch:\")\n",
        "    print(loss_by_epoch.detach().numpy())\n",
        "    if ((epoch <= 0) or (loss_by_epoch.detach().numpy() <= train_losses[-1])):\n",
        "      num_epoch_saved=num_epoch_saved+1\n",
        "      #Save model\n",
        "      torch.save(model.state_dict(), save_dir)\n",
        "      print('saved')\n",
        "      #Loss by batch Train\n",
        "      train_losses.append(loss_by_epoch.detach().numpy())\n",
        "\n",
        "      running_train_losses.append(loss_by_input) #New\n",
        "\n",
        "      #Accuracy by batch Train\n",
        "      accuracy = correct / total\n",
        "      train_accuracy.append(accuracy)\n",
        "      print(f\"Epoch {epoch+1}/{num_epoch}, Accuracy: {accuracy}\")\n",
        "\n",
        "      #Test\n",
        "      model.eval()\n",
        "      loss_test = 0.0\n",
        "      correct2 = 0\n",
        "      total2 = 0\n",
        "\n",
        "      with torch.no_grad():\n",
        "        for inputs, labels in test:\n",
        "          outputs = model(inputs)\n",
        "\n",
        "          test_size+=1\n",
        "\n",
        "          #Loss Test\n",
        "          loss_test = criterion(outputs, labels)\n",
        "          loss_by_input_test=loss_test.item()#New\n",
        "          loss_test += loss_test.item()\n",
        "\n",
        "          running_test_losses.append(loss_by_input_test)#New\n",
        "\n",
        "          #Accuracy Test\n",
        "          total2 += labels.size(0)\n",
        "          _, predicted2 = torch.max(outputs.data, 1)\n",
        "          correct2 += (predicted2 == labels).sum().item()\n",
        "\n",
        "        loss_by_epoch2=loss_test / len(test)\n",
        "        test_losses.append(loss_by_epoch2.detach().numpy())\n",
        "\n",
        "        accuracy2 = correct2 / total2\n",
        "        test_accuracy.append(accuracy2)\n",
        "        print(test_size)\n",
        "\n",
        "      print(\"Test end\")\n",
        "\n",
        "print(num_epoch)\n",
        "print(len(train_losses))\n",
        "print(len(test_losses))\n",
        "\n",
        "\n",
        "#Save model\n",
        "torch.save(model.state_dict(), save_dir)\n",
        "print('saved')\n",
        "\n",
        "#del model\n",
        "#torch.cuda.empty_cache()\n",
        "\n",
        "# Plot Loss Train\n",
        "plt.plot(range(1, num_epoch_saved+1), train_losses, label='Training Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Training Loss')\n",
        "plt.title('Training Loss By Epoch')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Plot Accuracy Train\n",
        "plt.plot(range(1, num_epoch_saved+1), train_accuracy , label='Training Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Training Accuracy')\n",
        "plt.title('Training Accuracy By Epoch')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Plot Loss Test\n",
        "plt.plot(range(1, num_epoch_saved+1), test_losses, label='Testing Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Testing Loss')\n",
        "plt.title('Testing Loss By Epoch')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Plot Accuracy Test\n",
        "plt.plot(range(1, num_epoch_saved+1), test_accuracy , label='Testing Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Testing Accuracy')\n",
        "plt.title('Testing Accuracy By Epoch')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "#By input\n",
        "plt.plot(range(1, len(running_train_losses)+1), running_train_losses, label='Training Loss by Inputs')\n",
        "plt.xlabel('Inputs')\n",
        "plt.ylabel('Training Loss')\n",
        "plt.title('Training Loss By Inputs')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.plot(range(1, len(running_test_losses)+1), running_test_losses, label='Testing Loss by Inputs')\n",
        "plt.xlabel('Inputs')\n",
        "plt.ylabel('Testing Loss')\n",
        "plt.title('Testing Loss By Inputs')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "XDwrQFSFBX8Y",
        "outputId": "90922449-c4fb-4410-ff7a-bb88652118b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 1.0976892709732056\n",
            "Epoch 1/10, Loss: 2.6914896965026855\n",
            "Epoch 1/10, Loss: 2.0665268898010254\n",
            "Epoch 1/10, Loss: 1.8049589395523071\n",
            "Epoch 1/10, Loss: 3.189069986343384\n",
            "Epoch 1/10, Loss: 1.0248634815216064\n",
            "Epoch 1/10, Loss: 0.9002000093460083\n",
            "Epoch 1/10, Loss: 0.5329868197441101\n",
            "This epoch:\n",
            "0.1332467\n",
            "saved\n",
            "Epoch 1/10, Accuracy: 0.4322033898305085\n",
            "7\n",
            "Test end\n",
            "Epoch 2/10, Loss: 0.7774129509925842\n",
            "Epoch 2/10, Loss: 0.746524453163147\n",
            "Epoch 2/10, Loss: 0.9423298835754395\n",
            "Epoch 2/10, Loss: 0.7832517027854919\n",
            "Epoch 2/10, Loss: 1.0640789270401\n",
            "Epoch 2/10, Loss: 0.6023486256599426\n",
            "Epoch 2/10, Loss: 0.5040721893310547\n",
            "Epoch 2/10, Loss: 1.5089654922485352\n",
            "This epoch:\n",
            "0.37724137\n",
            "Epoch 3/10, Loss: 0.7653570175170898\n",
            "Epoch 3/10, Loss: 0.7280060052871704\n",
            "Epoch 3/10, Loss: 0.5629312992095947\n",
            "Epoch 3/10, Loss: 0.7112966775894165\n",
            "Epoch 3/10, Loss: 0.4614943861961365\n",
            "Epoch 3/10, Loss: 0.46634212136268616\n",
            "Epoch 3/10, Loss: 0.8399976491928101\n",
            "Epoch 3/10, Loss: 0.6065542101860046\n",
            "This epoch:\n",
            "0.15163855\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-c66560cb9532>\u001b[0m in \u001b[0;36m<cell line: 23>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m       \u001b[0mloss_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m       \u001b[0mloss_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    490\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             )\n\u001b[0;32m--> 492\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    493\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    252\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Test\n",
        "#Load model\n",
        "model_name_to_load = 'model.pth'\n",
        "save_dir=F\"/content/drive/My Drive/Colab Notebooks/Saved models/Latest save/{model_name_to_load}\"\n",
        "\n",
        "state_dict = torch.load(save_dir)\n",
        "model.load_state_dict(state_dict)\n",
        "\n",
        "print('Test')\n",
        "labels_array = []\n",
        "predictions = []\n",
        "\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "  for inputs, labels in test:\n",
        "    outputs = model(inputs)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    labels_array.extend(labels.cpu().numpy())\n",
        "    predictions.extend(predicted.cpu().numpy())\n",
        "\n",
        "    #labels.extend(labels.cuda().numpy())\n",
        "    #predictions.extend(predicted.cuda().numpy())\n",
        "print(\"end\")\n",
        "\n",
        "# Confusion matrix\n",
        "c_matrix = confusion_matrix(labels_array, predictions, labels=[0, 1, 2])\n",
        "disp = ConfusionMatrixDisplay(c_matrix, display_labels=['NORM', 'MUS', 'STR'])\n",
        "disp.plot(cmap='Blues', values_format='d')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "#Classification report\n",
        "print(\"On Testing Data\")\n",
        "print(classification_report(labels_array, predictions, target_names=['NORM', 'MUS', 'STR']))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 735
        },
        "id": "6Cy9oL_4Vb7_",
        "outputId": "615c0158-e6e6-448f-fe1f-95b179ba197b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "end\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhQAAAHHCAYAAADnOMH5AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABRNElEQVR4nO3deVhUZf8G8HsGZQaBAURlUUDcEFxzSREVNBRNzS1XKhCt3A2XFMsNF8pSXELNMkAT15TcMg1FU3FfMjVcU1RAwwBFWYTz+8OX+TUCynCGMzDcn65zvc5znnOe74EX+fpsRyYIggAiIiIiEeT6DoCIiIjKPyYUREREJBoTCiIiIhKNCQURERGJxoSCiIiIRGNCQURERKIxoSAiIiLRmFAQERGRaEwoiIiISDQmFERl1LVr19C1a1dYWFhAJpMhOjpap/f/+++/IZPJEBERodP7lmdeXl7w8vLSdxhE5RITCqJXuHHjBj7++GPUqVMHSqUSKpUKHh4eWLp0KZ49e1aqbfv5+eHixYuYP38+1q1bh1atWpVqe1Ly9/eHTCaDSqUq9Ot47do1yGQyyGQyfP3111rf//79+5g9ezbOnz+vg2iJqDgq6TsAorJq9+7dGDBgABQKBT744AM0btwY2dnZOHLkCKZMmYJLly5h9erVpdL2s2fPEBcXh88++wxjx44tlTacnJzw7NkzVK5cuVTu/zqVKlXC06dPsXPnTgwcOFDj3Pr166FUKpGZmVmie9+/fx9z5sxB7dq10bx582Jft2/fvhK1R0RMKIgKdevWLQwePBhOTk44cOAA7Ozs1OfGjBmD69evY/fu3aXW/sOHDwEAlpaWpdaGTCaDUqkstfu/jkKhgIeHBzZs2FAgoYiKikKPHj3w008/SRLL06dPUaVKFRgbG0vSHpEh4pAHUSEWLlyIJ0+eYM2aNRrJRL569ephwoQJ6s/Pnz/H3LlzUbduXSgUCtSuXRvTp09HVlaWxnW1a9dGz549ceTIEbz55ptQKpWoU6cO1q5dq64ze/ZsODk5AQCmTJkCmUyG2rVrA3gxVJD/5/+aPXs2ZDKZRtn+/fvRvn17WFpawszMDC4uLpg+fbr6fFFzKA4cOIAOHTrA1NQUlpaW6N27N65cuVJoe9evX4e/vz8sLS1hYWGBYcOG4enTp0V/YV8ydOhQ/PLLL0hNTVWXnTp1CteuXcPQoUML1H/06BEmT56MJk2awMzMDCqVCt27d8eFCxfUdWJjY9G6dWsAwLBhw9RDJ/nP6eXlhcaNG+PMmTPo2LEjqlSpov66vDyHws/PD0qlssDz+/j4wMrKCvfv3y/2sxIZOiYURIXYuXMn6tSpg3bt2hWr/ogRIzBz5ky0aNECoaGh8PT0REhICAYPHlyg7vXr1/Huu++iS5cuWLRoEaysrODv749Lly4BAPr164fQ0FAAwJAhQ7Bu3TosWbJEq/gvXbqEnj17IisrC8HBwVi0aBHeeecdHD169JXX/fbbb/Dx8cGDBw8we/ZsTJw4EceOHYOHhwf+/vvvAvUHDhyIx48fIyQkBAMHDkRERATmzJlT7Dj79esHmUyGbdu2qcuioqLQsGFDtGjRokD9mzdvIjo6Gj179sTixYsxZcoUXLx4EZ6enupf7q6urggODgYAfPTRR1i3bh3WrVuHjh07qu+TkpKC7t27o3nz5liyZAk6depUaHxLly5F9erV4efnh9zcXADAt99+i3379mH58uWwt7cv9rMSGTyBiDSkpaUJAITevXsXq/758+cFAMKIESM0yidPniwAEA4cOKAuc3JyEgAIhw8fVpc9ePBAUCgUwqRJk9Rlt27dEgAIX331lcY9/fz8BCcnpwIxzJo1S/jvj3NoaKgAQHj48GGRcee3ER4eri5r3ry5UKNGDSElJUVdduHCBUEulwsffPBBgfYCAgI07tm3b1/B2tq6yDb/+xympqaCIAjCu+++K7z11luCIAhCbm6uYGtrK8yZM6fQr0FmZqaQm5tb4DkUCoUQHBysLjt16lSBZ8vn6ekpABBWrVpV6DlPT0+Nsl9//VUAIMybN0+4efOmYGZmJvTp0+e1z0hU0bCHgugl6enpAABzc/Ni1d+zZw8AYOLEiRrlkyZNAoACcy3c3NzQoUMH9efq1avDxcUFN2/eLHHML8ufe/Hzzz8jLy+vWNckJibi/Pnz8Pf3R9WqVdXlTZs2RZcuXdTP+V8jR47U+NyhQwekpKSov4bFMXToUMTGxiIpKQkHDhxAUlJSocMdwIt5F3L5i7+2cnNzkZKSoh7OOXv2bLHbVCgUGDZsWLHqdu3aFR9//DGCg4PRr18/KJVKfPvtt8Vui6iiYEJB9BKVSgUAePz4cbHq3759G3K5HPXq1dMot7W1haWlJW7fvq1R7ujoWOAeVlZW+Pfff0sYcUGDBg2Ch4cHRowYARsbGwwePBibN29+ZXKRH6eLi0uBc66urvjnn3+QkZGhUf7ys1hZWQGAVs/y9ttvw9zcHJs2bcL69evRunXrAl/LfHl5eQgNDUX9+vWhUChQrVo1VK9eHX/88QfS0tKK3WbNmjW1moD59ddfo2rVqjh//jyWLVuGGjVqFPtaooqCCQXRS1QqFezt7fHnn39qdd3LkyKLYmRkVGi5IAglbiN/fD+fiYkJDh8+jN9++w3vv/8+/vjjDwwaNAhdunQpUFcMMc+ST6FQoF+/foiMjMT27duL7J0AgAULFmDixIno2LEjfvzxR/z666/Yv38/GjVqVOyeGODF10cb586dw4MHDwAAFy9e1OpaooqCCQVRIXr27IkbN24gLi7utXWdnJyQl5eHa9euaZQnJycjNTVVvWJDF6ysrDRWROR7uRcEAORyOd566y0sXrwYly9fxvz583HgwAEcPHiw0HvnxxkfH1/g3F9//YVq1arB1NRU3AMUYejQoTh37hweP35c6ETWfFu3bkWnTp2wZs0aDB48GF27doW3t3eBr0lxk7viyMjIwLBhw+Dm5oaPPvoICxcuxKlTp3R2fyJDwYSCqBCffvopTE1NMWLECCQnJxc4f+PGDSxduhTAiy57AAVWYixevBgA0KNHD53FVbduXaSlpeGPP/5QlyUmJmL79u0a9R49elTg2vwNnl5eyprPzs4OzZs3R2RkpMYv6D///BP79u1TP2dp6NSpE+bOnYtvvvkGtra2RdYzMjIq0PuxZcsW3Lt3T6MsP/EpLPnS1tSpU3Hnzh1ERkZi8eLFqF27Nvz8/Ir8OhJVVNzYiqgQdevWRVRUFAYNGgRXV1eNnTKPHTuGLVu2wN/fHwDQrFkz+Pn5YfXq1UhNTYWnpydOnjyJyMhI9OnTp8gliSUxePBgTJ06FX379sX48ePx9OlTrFy5Eg0aNNCYlBgcHIzDhw+jR48ecHJywoMHD7BixQrUqlUL7du3L/L+X331Fbp37w53d3cMHz4cz549w/Lly2FhYYHZs2fr7DleJpfL8fnnn7+2Xs+ePREcHIxhw4ahXbt2uHjxItavX486depo1Ktbty4sLS2xatUqmJubw9TUFG3atIGzs7NWcR04cAArVqzArFmz1MtYw8PD4eXlhRkzZmDhwoVa3Y/IoOl5lQlRmXb16lXhww8/FGrXri0YGxsL5ubmgoeHh7B8+XIhMzNTXS8nJ0eYM2eO4OzsLFSuXFlwcHAQgoKCNOoIwotloz169CjQzsvLFYtaNioIgrBv3z6hcePGgrGxseDi4iL8+OOPBZaNxsTECL179xbs7e0FY2Njwd7eXhgyZIhw9erVAm28vLTyt99+Ezw8PAQTExNBpVIJvXr1Ei5fvqxRJ7+9l5elhoeHCwCEW7duFfk1FQTNZaNFKWrZ6KRJkwQ7OzvBxMRE8PDwEOLi4gpd7vnzzz8Lbm5uQqVKlTSe09PTU2jUqFGhbf73Punp6YKTk5PQokULIScnR6NeYGCgIJfLhbi4uFc+A1FFIhMELWZPERERERWCcyiIiIhINCYUREREJBoTCiIiIhKNCQURERGJxoSCiIiIRGNCQURERKJxYysdyMvLw/3792Fubq7TLX+JiEgagiDg8ePHsLe3V7/RtjRkZmYiOztb9H2MjY2hVCp1EJEO6XkfDIOQkJAgAODBgwcPHuX8SEhIKLXfFc+ePRNQqYpO4rS1tRWePXtWrHafP38ufP7550Lt2rUFpVIp1KlTRwgODhby8vLUdfLy8oQZM2YItra2glKpFN566y2NjfCKgz0UOmBubg4AOP3nTZj9789kuPZdT9J3CCShKdN+0HcIJAEhNwvZZ1eo/z4vDdnZ2cDzp1C4+QFGxiW/UW42ki5HIjs7u1i9FF9++SVWrlyJyMhINGrUCKdPn8awYcNgYWGB8ePHAwAWLlyIZcuWITIyEs7OzpgxYwZ8fHxw+fLlYveEMKHQgfxhDjNzc5irVHqOhkqbiWmGvkMgCckqKfQdAklIkmHrSkrIRCQUgky7IZljx46hd+/e6hcV1q5dGxs2bMDJkydf3E8QsGTJEnz++efo3bs3AGDt2rWwsbFBdHT0K98A/F+clElERCQlGQCZTMShXXPt2rVDTEwMrl69CgC4cOECjhw5gu7duwMAbt26haSkJHh7e6uvsbCwQJs2bRAXF1fsdthDQUREJCWZ/MUh5noA6enpGsUKhQIKRcEetWnTpiE9PR0NGzaEkZERcnNzMX/+fPj6+gIAkpJeDOPa2NhoXGdjY6M+VxzsoSAiIiqHHBwcYGFhoT5CQkIKrbd582asX78eUVFROHv2LCIjI/H1118jMjJSp/Gwh4KIiEhK+UMXYq4HkJCQANV/5u0V1jsBAFOmTMG0adPUcyGaNGmC27dvIyQkBH5+frC1tQUAJCcnw87OTn1dcnIymjdvXuyw2ENBREQkpfwhDzEHAJVKpXEUlVA8ffq0wN4aRkZGyMvLAwA4OzvD1tYWMTEx6vPp6ek4ceIE3N3di/1Y7KEgIiIyYL169cL8+fPh6OiIRo0a4dy5c1i8eDECAgIAvFjZ8sknn2DevHmoX7++etmovb09+vTpU+x2mFAQERFJSUdDHsW1fPlyzJgxA6NHj8aDBw9gb2+Pjz/+GDNnzlTX+fTTT5GRkYGPPvoIqampaN++Pfbu3avVbpxMKIiIiCQlcpWHlrMVzM3NsWTJEixZsqTIOjKZDMHBwQgODpYoKiIiIqJCsIeCiIhIShIPeUiFCQUREZGUdLSxVVlTNqMiIiKicoU9FERERFLikAcRERGJZqBDHkwoiIiIpGSgPRRlM80hIiKicoU9FERERFLikAcRERGJJpOJTCg45EFEREQGij0UREREUpLLXhxiri+DmFAQERFJyUDnUJTNqIiIiKhcYQ8FERGRlAx0HwomFERERFLikAcRERFR4dhDQUREJCUOeRAREZFoBjrkwYSCiIhISgbaQ1E20xwiIiIqV9hDQUREJCUOeRAREZFoHPIgIiIiKhx7KIiIiCQlcsijjPYFMKEgIiKSEoc8iIiIiArHHgoiIiIpyWQiV3mUzR4KJhRERERSMtBlo2UzKiIiIipX2ENBREQkJQOdlMmEgoiISEoGOuTBhIKIiEhKBtpDUTbTHCIiIipX2ENBREQkJQMd8iibURERERmq/CEPMYcWateuDZlMVuAYM2YMACAzMxNjxoyBtbU1zMzM0L9/fyQnJ2v9WEwoiIiIDNipU6eQmJioPvbv3w8AGDBgAAAgMDAQO3fuxJYtW3Do0CHcv38f/fr107odDnkQERFJKL+HQMQNtKpevXp1jc9ffPEF6tatC09PT6SlpWHNmjWIiopC586dAQDh4eFwdXXF8ePH0bZt22K3wx4KIiIiCRU2/KDtAQDp6ekaR1ZW1mvbzs7Oxo8//oiAgADIZDKcOXMGOTk58Pb2Vtdp2LAhHB0dERcXp9VzMaEgIiIqhxwcHGBhYaE+QkJCXntNdHQ0UlNT4e/vDwBISkqCsbExLC0tNerZ2NggKSlJq3g45EFERCQl2f8OMdcDSEhIgEqlUhcrFIrXXrpmzRp0794d9vb2IgIoHBMKIiIiCelqDoVKpdJIKF7n9u3b+O2337Bt2zZ1ma2tLbKzs5GamqrRS5GcnAxbW1utwuKQBxERUQUQHh6OGjVqoEePHuqyli1bonLlyoiJiVGXxcfH486dO3B3d9fq/uyhICIikpDUqzwAIC8vD+Hh4fDz80OlSv//q9/CwgLDhw/HxIkTUbVqVahUKowbNw7u7u5arfAAmFAQERFJSh8JxW+//YY7d+4gICCgwLnQ0FDI5XL0798fWVlZ8PHxwYoVK7RugwkFaa3j4Lm4l/xvgfL3entgzif99RAR6cLvh87hyOHzeJSSDgCwtbNGtx7t0KhxHQDA0d8v4PTJK7ibkIzMzGx8uXgcqlRR6jNkKqELmz6Fo51VgfLvt8dhSugO1KhqhuBRb8OrVT2YVVHgesJDLFp3EDsPXdJDtIZHHwlF165dIQhCoeeUSiXCwsIQFhZW8pig5zkU/v7+kMlk+OKLLzTKo6OjNb7Yubm5CA0NRZMmTaBUKmFlZYXu3bvj6NGjGtdFRESov1FyuRx2dnYYNGgQ7ty5o1HPy8ur0HYBoEePHpDJZJg9e7buHtTAbF8ViOM/zVYfa78eCQDo7tVMz5GRGJZW5ninjyemBH2AKUHvo4GLE75buR2J9/8BAGRn58C1kTO6dNOuG5TKns4fhcGlz3z10SfwewBA9MGLAICVnw1EPcdqGDp9LTz8l2Dn4UsInz0UTerb6TNsKuP0PilTqVTiyy+/xL//FvwXLwAIgoDBgwcjODgYEyZMwJUrVxAbGwsHBwd4eXkhOjpao75KpUJiYiLu3buHn376CfHx8ertRf/LwcEBERERGmX37t1DTEwM7Oz4Q/Mq1pZmqF5VpT4OxF2Co7012jSrq+/QSIQmTeuhUZM6qGFjhRo2VdGrTwcoFMb4+9Z9AECnt1qha7c2cHbmz0d5l5KWgQePnqgPn3auuHk3BUfP3wIAvNnIEd/9FIezV+7iduK/WLT2INKeZKJ5g5p6jtxAyHRwlEF6Tyi8vb1ha2tb5IYcmzdvxtatW7F27VqMGDECzs7OaNasGVavXo133nkHI0aMQEZGhrq+TCaDra0t7Ozs0K5dOwwfPhwnT55Eenq6xn179uyJf/75R6OXIzIyEl27dkWNGjVK52ENUHbOc/y8/ywGdG8jrguPypS8vDycOXUF2dk5qO2s+/XqVHZUrmSEgV2aY/2e0+qyk5fuoG/nprA0N4FMJkO/zk2hMK6EI/9LOEgcXe2UWdboPaEwMjLCggULsHz5cty9e7fA+aioKDRo0AC9evUqcG7SpElISUlRv+jkZQ8ePMD27dthZGQEIyMjjXPGxsbw9fVFeHi4uiwiIqLQCStUtP1H/kT6k2fo3621vkMhHbh/7yEmTViCwLGLsSlqP0Z83Ad29tX0HRaVoh4d3GBhpkTUL2fUZcNmRaFSJTlu7Z6J5Ji5CJ3cF+9//iNu3UvRY6RU1uk9oQCAvn37onnz5pg1a1aBc1evXoWrq2uh1+WXX716VV2WlpYGMzMzmJqawsbGBgcPHsSYMWNgampa4PqAgABs3rwZGRkZOHz4MNLS0tCzZ8/XxpuVlVVgD/WKasueE/Bs0xA21Sz0HQrpQA2bqpj2mR8mTX0P7Ts2x4+Re9RzKMgwvdejFX47cRVJKY/VZZ8N7wILMxP0/uR7dP7wG4RtPoLw2UPgVsdGj5EajhdvIBfTQ6HvJyhcmUgoAODLL79EZGQkrly5UuBcUTNTC2Nubo7z58/j9OnTWLRoEVq0aIH58+cXWrdZs2aoX78+tm7dih9++AHvv/++xvrcooSEhGjsn+7g4FDs+AzJvaRHOHr2Kga+zUl6hqJSJSNUr2EFRydbvNO3I+xrVcehg2defyGVSw42lvBqWQ9rd59Sl9W2r4qP+rfDuC+24vDZG/jzRhIWRsTgXPw9jOir3UZHVDgZRA55lNFJFGUmoejYsSN8fHwQFBSkUd6gQYNCkwwA6vIGDRqoy+RyOerVqwdXV1dMnDgRbdu2xahRo4psNyAgAGFhYdi6dWuxhzuCgoKQlpamPhISEop1naHZuvckrC3N0Mm98B4kKv8EAcjJydV3GFRKhr7dEg9Tn2BfXLy6rIqyMgAg76V/yOXm5ZXZsXsqG8pMQgG8eEf7zp07NV6ZOnjwYFy7dg07d+4sUH/RokWwtrZGly5dirzntGnTsGnTJpw9e7bQ80OHDsXFixfRuHFjuLm5FStOhUKh3kNd273UDUVeXh627j2Ffj6tUeml+SlUPu3YfhjXryUg5Z803L/38MXnq3fQ+s0XPxfpaU9wNyEZDx+mAgDu3/sHdxOSkZHxTI9RU0nJZDL4dm+JjXvPIjc3T11+9fZD3Lj7D0In90UL11qobV8VYwa1R6dW9bDnyGU9Rmw4DHVSZpna2KpJkybw9fXFsmXL1GWDBw/Gli1b4Ofnh6+++gpvvfUW0tPTERYWhh07dmDLli2Fzo/I5+DggL59+2LmzJnYtWtXgfNWVlZITExE5cqVS+WZDNXRM9dwP/lfDOj+pr5DIR15/Pgp1oXvQXp6BpQmCtjXrIbR4wagoVttAMCRwxfwy+5j6vpLF20AAPh+0B1t2zXWR8gkglerenCwtcKPuzWHtJ7n5mHgpxGY9XE3bAj5AKYmCty6l4LRC7Zi//H4Iu5GWtHR20bLmjKVUABAcHAwNm3apP4sk8mwefNmLFmyBKGhoRg9ejSUSiXc3d0RGxsLDw+P194zMDAQ7u7uOHnyJN58s+AvwJffA0+v16G1C24cXKzvMEiHfD/o9srzb/fywNu9Xv/zRuXDwVPXYNUxqNBzN++mwG/GeokjovJOJmgz45EKlZ6eDgsLC/x1+yHMK+DwR0WzJz5R3yGQhMYFrtJ3CCQB4XkWsk6FIi0trdSGsfN/V1gNWQO5cZUS3ycv+yn+3TC8VGMtiTLXQ0FERGTIxM6D4BwKIiIiMtiEokyt8iAiIqLyiT0UREREUuIqDyIiIhKLQx5ERERERWAPBRERkYQMtYeCCQUREZGEDDWh4JAHERERicYeCiIiIgkZag8FEwoiIiIpGeiyUQ55EBERkWjsoSAiIpIQhzyIiIhINCYUREREJJqhJhScQ0FERESisYeCiIhISga6yoMJBRERkYQ45EFERERUBPZQEBERSchQeyiYUBAREUlIBpEJRRmdRMEhDyIiIhKNPRREREQS4pAHERERiWegy0Y55EFERGTg7t27h/feew/W1tYwMTFBkyZNcPr0afV5QRAwc+ZM2NnZwcTEBN7e3rh27ZpWbTChICIiklD+kIeYQxv//vsvPDw8ULlyZfzyyy+4fPkyFi1aBCsrK3WdhQsXYtmyZVi1ahVOnDgBU1NT+Pj4IDMzs9jtcMiDiIhIQlLPofjyyy/h4OCA8PBwdZmzs7P6z4IgYMmSJfj888/Ru3dvAMDatWthY2OD6OhoDB48uFjtsIeCiIhIQjKZ+AMA0tPTNY6srKxC29uxYwdatWqFAQMGoEaNGnjjjTfw3Xffqc/funULSUlJ8Pb2VpdZWFigTZs2iIuLK/ZzMaEgIiIqhxwcHGBhYaE+QkJCCq138+ZNrFy5EvXr18evv/6KUaNGYfz48YiMjAQAJCUlAQBsbGw0rrOxsVGfKw4OeRAREUnoRS+DmCGPF/+bkJAAlUqlLlcoFIXWz8vLQ6tWrbBgwQIAwBtvvIE///wTq1atgp+fX4njeBl7KIiIiKQkdrjjfwmFSqXSOIpKKOzs7ODm5qZR5urqijt37gAAbG1tAQDJyckadZKTk9XnioMJBRERkQHz8PBAfHy8RtnVq1fh5OQE4MUETVtbW8TExKjPp6en48SJE3B3dy92OxzyICIikpDUqzwCAwPRrl07LFiwAAMHDsTJkyexevVqrF69Wn2/Tz75BPPmzUP9+vXh7OyMGTNmwN7eHn369Cl2O0woiIiIJPTflRolvV4brVu3xvbt2xEUFITg4GA4OztjyZIl8PX1Vdf59NNPkZGRgY8++gipqalo37499u7dC6VSWex2mFAQEREZuJ49e6Jnz55FnpfJZAgODkZwcHCJ22BCQUREJCG5XAa5vORdFIKIa0sTEwoiIiIJST3kIRWu8iAiIiLR2ENBREQkIalXeUiFCQUREZGEDHXIgwkFERGRhAy1h4JzKIiIiEg09lAQERFJyFB7KJhQEBERSchQ51BwyIOIiIhEYw8FERGRhGQQOeSBstlFwYSCiIhIQhzyICIiIioCeyiIiIgkxFUeREREJBqHPIiIiIiKwB4KIiIiCXHIg4iIiEQz1CEPJhREREQSMtQeCs6hICIiItHYQ6FDVmbGUJkZ6zsMKmXjvtin7xBIQgn75uo7BJLA4/R01KkZKk1jIoc8yuhGmUwoiIiIpMQhDyIiIqIisIeCiIhIQlzlQURERKJxyIOIiIioCOyhICIikhCHPIiIiEg0DnkQERERFYE9FERERBIy1B4KJhREREQS4hwKIiIiEs1Qeyg4h4KIiIhEYw8FERGRhAx1yIM9FERERBLKH/IQc2hj9uzZBa5v2LCh+nxmZibGjBkDa2trmJmZoX///khOTtb6uZhQEBERGbhGjRohMTFRfRw5ckR9LjAwEDt37sSWLVtw6NAh3L9/H/369dO6DQ55EBERSUgGkUMeJbimUqVKsLW1LVCelpaGNWvWICoqCp07dwYAhIeHw9XVFcePH0fbtm2L3QZ7KIiIiCQkl8lEH9q6du0a7O3tUadOHfj6+uLOnTsAgDNnziAnJwfe3t7qug0bNoSjoyPi4uK0aoM9FEREROVQenq6xmeFQgGFQlGgXps2bRAREQEXFxckJiZizpw56NChA/78808kJSXB2NgYlpaWGtfY2NggKSlJq3iYUBAREUlIV6s8HBwcNMpnzZqF2bNnF6jfvXt39Z+bNm2KNm3awMnJCZs3b4aJiUnJA3kJEwoiIiIJ6Wpjq4SEBKhUKnV5Yb0ThbG0tESDBg1w/fp1dOnSBdnZ2UhNTdXopUhOTi50zsWrcA4FERGRhOQy8QcAqFQqjaO4CcWTJ09w48YN2NnZoWXLlqhcuTJiYmLU5+Pj43Hnzh24u7tr9VzsoSAiIjJgkydPRq9eveDk5IT79+9j1qxZMDIywpAhQ2BhYYHhw4dj4sSJqFq1KlQqFcaNGwd3d3etVngATCiIiIikJRP5Pg4tL7179y6GDBmClJQUVK9eHe3bt8fx48dRvXp1AEBoaCjkcjn69++PrKws+Pj4YMWKFVqHxYSCiIhIQlJvvb1x48ZXnlcqlQgLC0NYWFjJgwLnUBAREZEOsIeCiIhIQrL//Sfm+rKICQUREZGE/rtSo6TXl0Uc8iAiIiLR2ENBREQkIV1tbFXWFCuh2LFjR7Fv+M4775Q4GCIiIkMn9SoPqRQroejTp0+xbiaTyZCbmysmHiIiIiqHipVQ5OXllXYcREREFUJJX0H+3+vLIlFzKDIzM6FUKnUVCxERkcEz1CEPrVd55ObmYu7cuahZsybMzMxw8+ZNAMCMGTOwZs0anQdIRERkSPInZYo5yiKtE4r58+cjIiICCxcuhLGxsbq8cePG+P7773UaHBEREZUPWicUa9euxerVq+Hr6wsjIyN1ebNmzfDXX3/pNDgiIiJDkz/kIeYoi7SeQ3Hv3j3Uq1evQHleXh5ycnJ0EhQREZGhMtRJmVr3ULi5ueH3338vUL5161a88cYbOgmKiIiIyheteyhmzpwJPz8/3Lt3D3l5edi2bRvi4+Oxdu1a7Nq1qzRiJCIiMhiy/x1iri+LtO6h6N27N3bu3InffvsNpqammDlzJq5cuYKdO3eiS5cupREjERGRwTDUVR4l2oeiQ4cO2L9/v65jISIionKqxBtbnT59GleuXAHwYl5Fy5YtdRYUERGRoTLU15drnVDcvXsXQ4YMwdGjR2FpaQkASE1NRbt27bBx40bUqlVL1zESEREZDEN926jWcyhGjBiBnJwcXLlyBY8ePcKjR49w5coV5OXlYcSIEaURIxEREZVxWvdQHDp0CMeOHYOLi4u6zMXFBcuXL0eHDh10GhwREZEhKqOdDKJonVA4ODgUuoFVbm4u7O3tdRIUERGRoeKQx/989dVXGDduHE6fPq0uO336NCZMmICvv/5ap8EREREZmvxJmWKOsqhYPRRWVlYaGVFGRgbatGmDSpVeXP78+XNUqlQJAQEB6NOnT6kESkRERGVXsRKKJUuWlHIYREREFYOhDnkUK6Hw8/Mr7TiIiIgqBEPdervEG1sBQGZmJrKzszXKVCqVqICIiIio/NE6ocjIyMDUqVOxefNmpKSkFDifm5urk8CIiIgMEV9f/j+ffvopDhw4gJUrV0KhUOD777/HnDlzYG9vj7Vr15ZGjERERAZDJhN/lEVa91Ds3LkTa9euhZeXF4YNG4YOHTqgXr16cHJywvr16+Hr61sacRIREVEZpnUPxaNHj1CnTh0AL+ZLPHr0CADQvn17HD58WLfRERERGRi+vvx/6tSpg1u3bsHR0RENGzbE5s2b8eabb2Lnzp3ql4WR4ftu8yEs/zEGD1LS0bh+TXw5ZQBaNqqt77BIhAthg+FYw7xA+fd7L2HKmmPw826Id9vXRVPnalBVMYaTXyTSn2YXcicqjxb/8AtCw3/VKKvrWAOx66frKSLDJXbYoozmE9onFMOGDcOFCxfg6emJadOmoVevXvjmm2+Qk5ODxYsXl0aMVMZs23cGny/ZjsXTBqFl49pYteEg+o8Lw6mtM1G9asFfSFQ+dA6KhtF/tuBzdbBC9MweiI67BQAwMa6EmPN3EXP+Lmb5vqmvMKkUNXC2xYbQ0erPlYy07sSmCkzr/7cEBgZi/PjxAABvb2/89ddfiIqKwrlz5zBhwgSdB/hf/v7+kMlkGDlyZIFzY8aMgUwmg7+/PwDAy8sLn3zySYF6ERERGj0pT58+RVBQEOrWrQulUonq1avD09MTP//8cyk9Rfm3IuoAPujTDr7vuKNhHTssDhqMKkpj/LgjTt+hkQgp6Zl4kPpMffi0dMTNpDQcvZwIAFi1508sib6AU1cf6DlSKi2VjOSoYa1SH1UtzfQdkkHKX+Uh5iiLRO1DAQBOTk5wcnLSRSzF4uDggI0bNyI0NBQmJiYAXuyHERUVBUdHR63vN3LkSJw4cQLLly+Hm5sbUlJScOzYsUKXxBKQnfMc5/9KQKB/V3WZXC6H55suOHXxlh4jI12qXEmOgR3qY8Wui/oOhSR06+4/aNlnJpTGldGicW1M+7gnatpY6Tssg1OhhzyWLVtW7Bvm916UlhYtWuDGjRvYtm2bekXJtm3b4OjoCGdnZ63vt2PHDixduhRvv/02AKB27dpo2bKlTmM2JCmpT5Cbm1dgaKN6VRWu/Z2sp6hI13q0rg0LU2NExV7VdygkkTfcnLB4+lDUdaiB5JQ0LIn4Ff3HLMNva6fCrIpS3+EZFH1uvf3FF18gKCgIEyZMUL9WIzMzE5MmTcLGjRuRlZUFHx8frFixAjY2Nlrdu1gJRWhoaLFuJpPJSj2hAICAgACEh4erE4offvgBw4YNQ2xsrNb3srW1xZ49e9CvXz+Ymxdv/D8rKwtZWVnqz+np6Vq3S1SWvdfZBb+dS0DSv0/1HQpJpFNbN/WfXevZ4w03J7gPCMauA+cxuGdbPUZGunLq1Cl8++23aNq0qUZ5YGAgdu/ejS1btsDCwgJjx45Fv379cPToUa3uX6yE4tatstWV/d577yEoKAi3b98GABw9ehQbN24sUUKxevVq+Pr6wtraGs2aNUP79u3x7rvvwsPDo8hrQkJCMGfOnJKGX65ZW5rByEiOh48ea5Q/fJSOGtbcdt0QOFQzg1dTe7z/1W/6DoX0yMK8CpwdquPvuw/1HYrBkaMEExhful5bT548ga+vL7777jvMmzdPXZ6WloY1a9YgKioKnTt3BgCEh4fD1dUVx48fR9u2xU8my+UU3urVq6NHjx6IiIhAeHg4evTogWrVqpXoXh07dsTNmzcRExODd999F5cuXUKHDh0wd+7cIq8JCgpCWlqa+khISCjpo5Q7xpUroXlDBxw6Fa8uy8vLw+FTV9G6ifZDTlT2DO3UAA/TMrHv7B19h0J6lPE0C7fvpaBGNf5DQdd0tQ9Fenq6xvHfnvOXjRkzBj169IC3t7dG+ZkzZ5CTk6NR3rBhQzg6OiIuTruJ9qInZepLQEAAxo4dCwAICwsrcF6lUiEtLa1AeWpqKiwsLDTKKleujA4dOqBDhw6YOnUq5s2bh+DgYEydOhXGxsYF7qFQKKBQKHT0JOXP6KGdMXrOOrzh6ogWjWpj5YaDyHiWBd9e7BYt72QywLdTA2w8dBW5eYLGuRqWJqhhaYI6ti9+wTRyrIrHmdm4+08GUp8U/RcZlQ9zw36Gd7tGqGVrheR/0rH4h19gJJeh91ucU1ZWOTg4aHyeNWsWZs+eXaDexo0bcfbsWZw6darAuaSkJBgbGxfYR8rGxgZJSUlaxVNuE4pu3bohOzsbMpkMPj4+Bc67uLhg3759BcrPnj2LBg0avPLebm5ueP78OTIzMwtNKCq6fl1b4p/UJ1jw7W48SHmMJg1qYuuyMRzyMABeTWrCobo5fjxQcDLmsC6umDbw/3+57JnbCwAwOiwWG2KvSRYjlY7EB6kYO2ctUtMzUNXSDK2b1MHP3wbC2opLR3VNJgPkOljlkZCQoPGG78L+oZuQkIAJEyZg//79UCpLd3JtuU0ojIyMcOXKFfWfXzZq1Ch88803GD9+PEaMGAGFQoHdu3djw4YN2Llzp7qel5cXhgwZglatWsHa2hqXL1/G9OnT0alTJ76K/RU+GuiJjwZ66jsM0rGDf9yD1YDvCj335Zaz+HLLWYkjIqmsmOOn7xAqDLnIhCL/WpVK9drfU2fOnMGDBw/QokULdVlubi4OHz6Mb775Br/++iuys7ORmpqq0UuRnJwMW1tbreIqtwkFgFd+IevUqYPDhw/js88+g7e3N7Kzs9GwYUNs2bIF3bp1U9fz8fFBZGQkpk+fjqdPn8Le3h49e/bEzJkzpXgEIiKiUvPWW2/h4kXN/WSGDRuGhg0bYurUqXBwcEDlypURExOD/v37AwDi4+Nx584duLu7a9VWiRKK33//Hd9++y1u3LiBrVu3ombNmli3bh2cnZ3Rvn37ktyyWCIiIl55Pjo6WuNz69atCx32+K+goCAEBQWJjIyIiKh4pNyHwtzcHI0bN9YoMzU1hbW1tbp8+PDhmDhxIqpWrQqVSoVx48bB3d1dqxUeQAlWefz000/w8fGBiYkJzp07p55VmpaWhgULFmh7OyIiogolf8hDzKFLoaGh6NmzJ/r374+OHTvC1tYW27Zt0/65tL1g3rx5WLVqFb777jtUrlxZXe7h4YGzZzm+SkREVJbFxsaqd8kEAKVSibCwMDx69AgZGRnYtm2b1vMngBIMecTHx6Njx44Fyi0sLJCamqp1AERERBWJob7LQ+seCltbW1y/fr1A+ZEjR1CnTh2dBEVERGSoDPVto1onFB9++CEmTJiAEydOQCaT4f79+1i/fj0mT56MUaNGlUaMREREBkOug6Ms0nrIY9q0acjLy8Nbb72Fp0+fomPHjlAoFJg8eTLGjRtXGjESERFRGad1QiGTyfDZZ59hypQpuH79Op48eQI3NzeYmXE3NSIiotcx1DkUJd7YytjYGG5ubq+vSERERGpyiJsHIUfZzCi0Tig6der0yk01Dhw4ICogIiIiKn+0TiiaN2+u8TknJwfnz5/Hn3/+CT8/7gVPRET0Khzy+J/Q0NBCy2fPno0nT56IDoiIiMiQ6erlYGWNzlafvPfee/jhhx90dTsiIiIqR3T2ttG4uLhSf9c6ERFReSeTQdSkTIMZ8ujXr5/GZ0EQkJiYiNOnT2PGjBk6C4yIiMgQcQ7F/1hYWGh8lsvlcHFxQXBwMLp27aqzwIiIiKj80CqhyM3NxbBhw9CkSRNYWVmVVkxEREQGi5MyARgZGaFr1658qygREVEJyXTwX1mk9SqPxo0b4+bNm6URCxERkcHL76EQc5RFWicU8+bNw+TJk7Fr1y4kJiYiPT1d4yAiIqKKp9hzKIKDgzFp0iS8/fbbAIB33nlHYwtuQRAgk8mQm5ur+yiJiIgMhKHOoSh2QjFnzhyMHDkSBw8eLM14iIiIDJpMJnvlO7GKc31ZVOyEQhAEAICnp2epBUNERETlk1bLRstqVkRERFReVPghDwBo0KDBa5OKR48eiQqIiIjIkHGnTLyYR/HyTplEREREWiUUgwcPRo0aNUorFiIiIoMnl8lEvRxMzLWlqdgJBedPEBERiWeocyiKvbFV/ioPIiIiopcVu4ciLy+vNOMgIiKqGEROyiyjr/LQ/vXlREREVHJyyCAXkRWIubY0MaEgIiKSkKEuG9X65WBEREREL2MPBRERkYQMdZUHEwoiIiIJGeo+FBzyICIiItHYQ0FERCQhQ52UyYSCiIhIQnKIHPIoo8tGOeRBRERkwFauXImmTZtCpVJBpVLB3d0dv/zyi/p8ZmYmxowZA2tra5iZmaF///5ITk7Wuh0mFERERBLKH/IQc2ijVq1a+OKLL3DmzBmcPn0anTt3Ru/evXHp0iUAQGBgIHbu3IktW7bg0KFDuH//Pvr166f1c3HIg4iISEJyiPvXvLbX9urVS+Pz/PnzsXLlShw/fhy1atXCmjVrEBUVhc6dOwMAwsPD4erqiuPHj6Nt27alFhcRERGVAenp6RpHVlbWa6/Jzc3Fxo0bkZGRAXd3d5w5cwY5OTnw9vZW12nYsCEcHR0RFxenVTxMKIiIiCQkk8lEHwDg4OAACwsL9RESElJkmxcvXoSZmRkUCgVGjhyJ7du3w83NDUlJSTA2NoalpaVGfRsbGyQlJWn1XBzyICIikpAM4l4Ymn9tQkICVCqVulyhUBR5jYuLC86fP4+0tDRs3boVfn5+OHTokIgoCmJCQUREJCFd7ZSZv2qjOIyNjVGvXj0AQMuWLXHq1CksXboUgwYNQnZ2NlJTUzV6KZKTk2Fra6tdXFrVJiIionIvLy8PWVlZaNmyJSpXroyYmBj1ufj4eNy5cwfu7u5a3ZM9FERERBKTcmuqoKAgdO/eHY6Ojnj8+DGioqIQGxuLX3/9FRYWFhg+fDgmTpyIqlWrQqVSYdy4cXB3d9dqhQfAhIKIiEhSUm+9/eDBA3zwwQdITEyEhYUFmjZtil9//RVdunQBAISGhkIul6N///7IysqCj48PVqxYoXVcTCiIiIgM2Jo1a155XqlUIiwsDGFhYaLaYUJBREQkof8u/Szp9WUREwoiIiIJSb1TplTKalxERERUjrCHgoiISEIc8iAiIiLRdLVTZlnDIQ8iIiISjT0URFpaPq2rvkMgCTl0+ETfIZAEhNxsydrikAcRERGJZqirPJhQEBERSchQeyjKaqJDRERE5Qh7KIiIiCRkqKs8mFAQERFJSOqXg0mFQx5EREQkGnsoiIiIJCSHDHIRAxdiri1NTCiIiIgkxCEPIiIioiKwh4KIiEhCsv/9J+b6sogJBRERkYQ45EFERERUBPZQEBERSUgmcpUHhzyIiIjIYIc8mFAQERFJyFATCs6hICIiItHYQ0FERCQhLhslIiIi0eSyF4eY68siDnkQERGRaOyhICIikhCHPIiIiEg0rvIgIiIiKgJ7KIiIiCQkg7hhizLaQcGEgoiISEpc5UFERERUBPZQEBERSYirPIiIiEg0rvIgIiIi0WQ6OLQREhKC1q1bw9zcHDVq1ECfPn0QHx+vUSczMxNjxoyBtbU1zMzM0L9/fyQnJ2vVDhMKIiIiA3bo0CGMGTMGx48fx/79+5GTk4OuXbsiIyNDXScwMBA7d+7Eli1bcOjQIdy/fx/9+vXTqh0OeRAREUlIDhnkIsYt5Fr2Uezdu1fjc0REBGrUqIEzZ86gY8eOSEtLw5o1axAVFYXOnTsDAMLDw+Hq6orjx4+jbdu2xYyLiIiIJKOrIY/09HSNIysrq1jtp6WlAQCqVq0KADhz5gxycnLg7e2trtOwYUM4OjoiLi6u2M/FhIKIiKgccnBwgIWFhfoICQl57TV5eXn45JNP4OHhgcaNGwMAkpKSYGxsDEtLS426NjY2SEpKKnY8HPIgIiKSUklmVr58PYCEhASoVCp1sUKheO2lY8aMwZ9//okjR46ICKBwTCiIiIgkpKt9KFQqlUZC8Tpjx47Frl27cPjwYdSqVUtdbmtri+zsbKSmpmr0UiQnJ8PW1rbY9+eQBxERkQETBAFjx47F9u3bceDAATg7O2ucb9myJSpXroyYmBh1WXx8PO7cuQN3d/dit8MeCiIiIimJ3NhK286NMWPGICoqCj///DPMzc3V8yIsLCxgYmICCwsLDB8+HBMnTkTVqlWhUqkwbtw4uLu7F3uFB8CEgoiISFI6mkJRbCtXrgQAeHl5aZSHh4fD398fABAaGgq5XI7+/fsjKysLPj4+WLFihVbtMKEgIiIyYIIgvLaOUqlEWFgYwsLCStwOEwoiIiIpSd1FIREmFERERBLi20aJiIhINL5tlIiIiKgI7KEgIiKSkIFOoWBCQUREJCkDzSg45EFERESisYeCiIhIQlzlQURERKJxlQcRERFREdhDQUREJCEDnZPJhIKIiEhSBppRcMiDiIiIRGMPBRERkYS4yoOIiIhEM9RVHkwoiIiIJGSgUyg4h4KIiIjEYw8Flch3mw9h+Y8xeJCSjsb1a+LLKQPQslFtfYdFIvx+6ByOHD6PRynpAABbO2t069EOjRrXAQAc/f0CTp+8grsJycjMzMaXi8ehShWlPkOmEpLLZZj20dsY2K01alirkPRPGqJ2ncDXa/aq6/Ts1AzD+rVH84aOqGppig6+Ifjz6j09Rm1ADLSLgj0UpLVt+87g8yXbMXVEd8Sum4rG9Wui/7gwPHz0WN+hkQiWVuZ4p48npgR9gClB76OBixO+W7kdiff/AQBkZ+fAtZEzunRrq+dISaxPPuiCgP4d8OlXW9Bm4DzMXv4zxr/vjY8GearrmCqNcfzCDcz+Jlp/gRoomQ7+K4vKdULx8OFDjBo1Co6OjlAoFLC1tYWPjw/mz58PmUz2yiM2NhYRERHqz3K5HHZ2dhg0aBDu3Lmj70cr01ZEHcAHfdrB9x13NKxjh8VBg1FFaYwfd8TpOzQSoUnTemjUpA5q2Fihhk1V9OrTAQqFMf6+dR8A0OmtVujarQ2cne30HCmJ9WbTOthz6A/sO3oJCYmPsOPAeRw88RdaNnJS19n0yyl89f1exJ6M12OkVJ6U64Sif//+OHfuHCIjI3H16lXs2LEDXl5eaNKkCRITE9XHwIED0a1bN42ydu3aAQBUKhUSExNx7949/PTTT4iPj8eAAQP0/GRlV3bOc5z/KwFeb7qoy+RyOTzfdMGpi7f0GBnpUl5eHs6cuoLs7BzUdrbXdzikYyf/uAnP1i6o61gDANC4fk20bVYHvx27rOfIKob8VR5ijrKo3M6hSE1Nxe+//47Y2Fh4er7opnNycsKbb75ZoK6JiQmysrJga2tb4JxMJlOX29nZYfjw4Rg/fjzS09OhUqlK9yHKoZTUJ8jNzUP1quYa5dWrqnDt72Q9RUW6cv/eQyxauB7Pc55DoTDGiI/7wM6+mr7DIh0LjdwPczMlTm75HLl5AozkMsxbuQtb9p7Wd2gVgoFOoSi/CYWZmRnMzMwQHR2Ntm3bQqFQiL7ngwcPsH37dhgZGcHIyKjIellZWcjKylJ/Tk9PF902UVlQw6Yqpn3mh2fPsnD+7FX8GLkH4ycOZlJhYPp6t8CAbq3x4eeR+OtmIpo0qIkFE99F4sM0bNx9Qt/hUTlVboc8KlWqhIiICERGRsLS0hIeHh6YPn06/vjjD63uk5aWBjMzM5iamsLGxgYHDx7EmDFjYGpqWuQ1ISEhsLCwUB8ODg5iH6fcsLY0g5GRvMAEzIeP0lHDmj065V2lSkaoXsMKjk62eKdvR9jXqo5DB8/oOyzSseAJfbAkcj+27T+DyzfuY9Mvp7BiwwEE+nfRd2gVg0wHRxlUbhMK4MUcivv372PHjh3o1q0bYmNj0aJFC0RERBT7Hubm5jh//jxOnz6NRYsWoUWLFpg/f/4rrwkKCkJaWpr6SEhIEPkk5Ydx5Upo3tABh079/0StvLw8HD51Fa2bOOsxMioNggDk5OTqOwzSMROFMfLy8jTK8vIEyGXl+ldCuWGoqzzK7ZBHPqVSiS5duqBLly6YMWMGRowYgVmzZsHf379Y18vlctSrVw8A4Orqihs3bmDUqFFYt25dkdcoFAqdDLGUV6OHdsboOevwhqsjWjSqjZUbDiLjWRZ8e3E5YXm2Y/thuDV2hpWVCllZ2Th98gquX72D0eNeTFJOT3uC9PQMPHyYCgC4f+8fKJWVYVVVBVNTEz1GTtrae+QiJg7zwd2kf3HlZiKautTC6KGdsH7HcXUdS1UV1LK1gl01CwBAfScbAMCDlHQ8SOEScSqo3CcUL3Nzc0N0dHSJr582bRrq1q2LwMBAtGjRQneBGZB+XVvin9QnWPDtbjxIeYwmDWpi67IxHPIo5x4/fop14XuQnp4BpYkC9jWrYfS4AWjoVhsAcOTwBfyy+5i6/tJFGwAAvh90R9t2jfURMpXQ1K+2YPrInvh66iBUszJD0j9piNh2FAu//0Vdp3vHJlgx63315x8WBAAAvli9B19+t0fymA0J3+VRxqSkpGDAgAEICAhA06ZNYW5ujtOnT2PhwoXo3bt3ie/r4OCAvn37YubMmdi1a5cOIzYsHw30xEcDPV9fkcoN3w+6vfL827088HYvD4miodL05GkWpi/+CdMX/1RknQ27TmDDLk7QLA1c5VHGmJmZoU2bNggNDcWNGzeQk5MDBwcHfPjhh5g+fbqoewcGBsLd3R0nT54sdBkqERFRiRloRiETBEHQdxDlXXp6OiwsLJCcksa9KyqAH8/c1ncIJKFxI7/SdwgkASE3G1kXv0NaWun9PZ7/u+LMtUSYmZe8jSeP09Gyvl2pxloS5baHgoiIqDwSu1KDqzyIiIgIELt9dtnMJ8r3PhRERERUNrCHgoiISEIGOieTCQUREZGkDDSj4JAHERGRATt8+DB69eoFe3t7yGSyAps/CoKAmTNnws7ODiYmJvD29sa1a9e0bocJBRERkYSkfpdHRkYGmjVrhrCwsELPL1y4EMuWLcOqVatw4sQJmJqawsfHB5mZmVq1wyEPIiIiCUm99Xb37t3RvXv3Qs8JgoAlS5bg888/V+8yvXbtWtjY2CA6OhqDBw8udjvsoSAiIiqH0tPTNY6srCyt73Hr1i0kJSXB29tbXWZhYYE2bdogLi5Oq3sxoSAiIpKQTAcH8OLdUxYWFuojJCRE61iSkpIAADY2NhrlNjY26nPFxSEPIiIiKelolUdCQoLG1tsKhUJUWGKxh4KIiEhCupqUqVKpNI6SJBS2trYAgOTkZI3y5ORk9bniYkJBRERUQTk7O8PW1hYxMTHqsvT0dJw4cQLu7u5a3YtDHkRERBKSQeQqDy3rP3nyBNevX1d/vnXrFs6fP4+qVavC0dERn3zyCebNm4f69evD2dkZM2bMgL29Pfr06aNVO0woiIiIJCT1RpmnT59Gp06d1J8nTpwIAPDz80NERAQ+/fRTZGRk4KOPPkJqairat2+PvXv3QqlUatUOEwoiIiID5uXlBUEQijwvk8kQHByM4OBgUe0woSAiIpKQ1BtbSYUJBRERkaQM8+1gXOVBREREorGHgoiISEIc8iAiIiLRDHPAg0MeREREpAPsoSAiIpIQhzyIiIhItP++j6Ok15dFTCiIiIikZKCTKDiHgoiIiERjDwUREZGEDLSDggkFERGRlAx1UiaHPIiIiEg09lAQERFJiKs8iIiISDwDnUTBIQ8iIiISjT0UREREEjLQDgomFERERFLiKg8iIiKiIrCHgoiISFLiVnmU1UEPJhREREQS4pAHERERURGYUBAREZFoHPIgIiKSkKEOeTChICIikpChbr3NIQ8iIiISjT0UREREEuKQBxEREYlmqFtvc8iDiIiIRGMPBRERkZQMtIuCCQUREZGEuMqDiIiIqAjsoSAiIpIQV3kQERGRaAY6hYJDHkRERJKS6eAogbCwMNSuXRtKpRJt2rTByZMnxT3HS5hQEBERGbhNmzZh4sSJmDVrFs6ePYtmzZrBx8cHDx480FkbTCiIiIgkJNPBf9pavHgxPvzwQwwbNgxubm5YtWoVqlSpgh9++EFnz8WEgoiISEL5kzLFHNrIzs7GmTNn4O3trS6Ty+Xw9vZGXFyczp6LkzJ1QBAEAMDj9HQ9R0JSeJbxWN8hkISE3Gx9h0ASyP8+5/99XprSRf6uyL/+5fsoFAooFIoC9f/55x/k5ubCxsZGo9zGxgZ//fWXqFj+iwmFDjx+/OIXTD1nBz1HQkREYjx+/BgWFhalcm9jY2PY2tqivg5+V5iZmcHBQfM+s2bNwuzZs0Xfu6SYUOiAvb09EhISYG5uDllZXSBcCtLT0+Hg4ICEhASoVCp9h0OliN/riqOifq8FQcDjx49hb29fam0olUrcunUL2dnie70EQSjw+6aw3gkAqFatGoyMjJCcnKxRnpycDFtbW9Gx5GNCoQNyuRy1atXSdxh6o1KpKtRfPBUZv9cVR0X8XpdWz8R/KZVKKJXKUm/nv4yNjdGyZUvExMSgT58+AIC8vDzExMRg7NixOmuHCQUREZGBmzhxIvz8/NCqVSu8+eabWLJkCTIyMjBs2DCdtcGEgoiIyMANGjQIDx8+xMyZM5GUlITmzZtj7969BSZqisGEgkpMoVBg1qxZRY7bkeHg97ri4PfacI0dO1anQxwvkwlSrJEhIiIig8aNrYiIiEg0JhREREQkGhMKIiIiEo0JBREREYnGhKKC8ff3h0wmwxdffKFRHh0drbHrWm5uLkJDQ9GkSRMolUpYWVmhe/fuOHr0qMZ1ERERkMlkkMlkkMvlsLOzw6BBg3Dnzh2Nel5eXoW2CwA9evSATCbT65axFUn+/wdGjhxZ4NyYMWMgk8ng7+8P4MX37ZNPPilQLyIiApaWlurPT58+RVBQEOrWrQulUonq1avD09MTP//8cyk9BWnr4cOHGDVqFBwdHaFQKGBrawsfHx/Mnz9f/TNc1BEbG1vsn3WquJhQVEBKpRJffvkl/v3330LPC4KAwYMHIzg4GBMmTMCVK1cQGxsLBwcHeHl5ITo6WqO+SqVCYmIi7t27h59++gnx8fEYMGBAgfs6ODggIiJCo+zevXuIiYmBnZ2drh6PisHBwQEbN27Es2fP1GWZmZmIioqCo6Oj1vcbOXIktm3bhuXLl+Ovv/7C3r178e677yIlJUWXYZMI/fv3x7lz5xAZGYmrV69ix44d8PLyQpMmTZCYmKg+Bg4ciG7dummUtWvXDkDxf9apYuI+FBWQt7c3rl+/jpCQECxcuLDA+c2bN2Pr1q3YsWMHevXqpS5fvXo1UlJSMGLECHTp0gWmpqYAAJlMpt4P3s7ODsOHD8f48eORnp6usXVvz549sXnzZhw9ehQeHh4AgMjISHTt2pX/ypFYixYtcOPGDWzbtg2+vr4AgG3btsHR0RHOzs5a32/Hjh1YunQp3n77bQBA7dq10bJlS53GTCWXmpqK33//HbGxsfD09AQAODk54c033yxQ18TEBFlZWYW+46G4P+tUMbGHogIyMjLCggULsHz5cty9e7fA+aioKDRo0EAjmcg3adIkpKSkYP/+/YXe+8GDB9i+fTuMjIxgZGSkcc7Y2Bi+vr4IDw9Xl0VERCAgIEDkE1FJBAQEaHwvfvjhhxJvw2tra4s9e/ao37xLZYuZmRnMzMwQHR2NrKwsndzzVT/rVDExoaig+vbti+bNm2PWrFkFzl29ehWurq6FXpdffvXqVXVZWloazMzMYGpqChsbGxw8eBBjxoxR92D8V0BAADZv3oyMjAwcPnwYaWlp6Nmzp46eirTx3nvv4ciRI7h9+zZu376No0eP4r333ivRvVavXo1jx47B2toarVu3RmBgYIH5NqQ/lSpVQkREBCIjI2FpaQkPDw9Mnz4df/zxh1b30eZnnSoeJhQV2JdffonIyEhcuXKlwDltNlA1NzfH+fPncfr0aSxatAgtWrTA/PnzC63brFkz1K9fH1u3bsUPP/yA999/H5UqceRNH6pXr44ePXogIiIC4eHh6NGjB6pVq1aie3Xs2BE3b95ETEwM3n33XVy6dAkdOnTA3LlzdRw1lVT//v1x//597NixA926dUNsbCxatGhRYF7Tq2jzs04VDxOKCqxjx47w8fFBUFCQRnmDBg0KTTIAqMsbNGigLpPL5ahXrx5cXV0xceJEtG3bFqNGjSqy3YCAAISFhWHr1q0c7tCzgIAA9b9cC/teqFQqpKWlFShPTU0t8KrnypUro0OHDpg6dSr27duH4OBgzJ07F9nZ2aUWP2lHqVSiS5cumDFjBo4dOwZ/f/9CeymLou3POlUsTCgquC+++AI7d+5EXFycumzw4MG4du0adu7cWaD+okWLYG1tjS5duhR5z2nTpmHTpk04e/ZsoeeHDh2KixcvonHjxnBzcxP/EFRi3bp1Q3Z2NnJycuDj41PgvIuLS6Hfx7Nnz2oklYVxc3PD8+fPkZmZqbN4Sbfc3NyQkZFR4utf97NOFQv7miu4Jk2awNfXF8uWLVOXDR48GFu2bIGfnx+++uorvPXWW0hPT0dYWBh27NiBLVu2vHLM1MHBAX379sXMmTOxa9euAuetrKyQmJiIypUrl8ozUfEZGRmpe50Km1g3atQofPPNNxg/fjxGjBgBhUKB3bt3Y8OGDRoJp5eXF4YMGYJWrVrB2toaly9fxvTp09GpUyfO/i8DUlJSMGDAAAQEBKBp06YwNzfH6dOnsXDhQvTu3bvE933dzzpVLEwoCMHBwdi0aZP6s0wmw+bNm7FkyRKEhoZi9OjRUCqVcHd3R2xsrHrJ56sEBgbC3d0dJ0+eLHRp2n83RSL9etUv/Dp16uDw4cP47LPP4O3tjezsbDRs2BBbtmxBt27d1PV8fHwQGRmJ6dOn4+nTp7C3t0fPnj0xc+ZMKR6BXsPMzAxt2rRBaGgobty4gZycHDg4OODDDz/E9OnTRd37dT/rVHHw9eVEREQkGudQEBERkWhMKIiIiEg0JhREREQkGhMKIiIiEo0JBREREYnGhIKIiIhEY0JBREREojGhIDIQ/v7+6NOnj/qzl5cXPvnkE8njiI2NhUwmQ2pqapF1ZDIZoqOji33P2bNno3nz5qLi+vvvvyGTyXD+/HlR9yGiwjGhICpF/v7+kMlkkMlkMDY2Rr169RAcHIznz5+Xetvbtm0r9ts+i5MEEBG9CrfeJipl3bp1Q3h4OLKysrBnzx6MGTMGlStXLvCWVwDIzs6GsbGxTtqtWrWqTu5DRFQc7KEgKmUKhQK2trZwcnLCqFGj4O3tjR07dgD4/2GK+fPnw97eHi4uLgCAhIQEDBw4EJaWlqhatSp69+6Nv//+W33P3NxcTJw4EZaWlrC2tsann36Kl3fRf3nIIysrC1OnToWDgwMUCgXq1auHNWvW4O+//0anTp0AvHhxm0wmg7+/PwAgLy8PISEhcHZ2homJCZo1a4atW7dqtLNnzx40aNAAJiYm6NSpk0acxTV16lQ0aNAAVapUQZ06dTBjxgzk5OQUqPftt9/CwcEBVapUwcCBAwu8Wv3777+Hq6srlEolGjZsiBUrVmgdCxGVDBMKIomZmJggOztb/TkmJgbx8fHYv38/du3apX6VuLm5OX7//XccPXoUZmZm6leNAy9eIx8REYEffvgBR44cwaNHj7B9+/ZXtvvBBx9gw4YNWLZsGa5cuYJvv/0WZmZmcHBwwE8//QQAiI+PR2JiIpYuXQoACAkJwdq1a7Fq1SpcunQJgYGBeO+993Do0CEALxKffv36oVevXjh//jxGjBiBadOmaf01MTc3R0REBC5fvoylS5fiu+++Q2hoqEad69evY/Pmzdi5cyf27t2Lc+fOYfTo0erz69evx8yZMzF//nxcuXIFCxYswIwZMxAZGal1PERUAgIRlRo/Pz+hd+/egiAIQl5enrB//35BoVAIkydPVp+3sbERsrKy1NesW7dOcHFxEfLy8tRlWVlZgomJifDrr78KgiAIdnZ2wsKFC9Xnc3JyhFq1aqnbEgRB8PT0FCZMmCAIgiDEx8cLAIT9+/cXGufBgwcFAMK///6rLsvMzBSqVKkiHDt2TKPu8OHDhSFDhgiCIAhBQUGCm5ubxvmpU6cWuNfLAAjbt28v8vxXX30ltGzZUv151qxZgpGRkXD37l112S+//CLI5XIhMTFREARBqFu3rhAVFaVxn7lz5wru7u6CIAjCrVu3BADCuXPnimyXiEqOcyiIStmuXbtgZmaGnJwc5OXlYejQoZg9e7b6fJMmTTTmTVy4cAHXr1+Hubm5xn0yMzNx48YNpKWlITExEW3atFGfq1SpElq1alVg2CPf+fPnYWRkBE9Pz2LHff36dTx9+hRdunTRKM/OzsYbb7wBALhy5YpGHADg7u5e7Dbybdq0CcuWLcONGzfw5MkTPH/+vMBr1R0dHVGzZk2NdvLy8hAfHw9zc3PcuHEDw4cPx4cffqiu8/z5c1hYWGgdDxFpjwkFUSnr1KkTVq5cCWNjY9jb26NSJc0fO1NTU43PT548QcuWLbF+/foC96pevXqJYjAxMdH6midPngAAdu/erfGLHHgxL0RX4uLi4Ovrizlz5sDHxwcWFhbYuHEjFi1apHWs3333XYEEx8jISGexElHRmFAQlTJTU1PUq1ev2PVbtGiBTZs2oUaNGgX+lZ7Pzs4OJ06cQMeOHQG8+Jf4mTNn0KJFi0LrN2nSBHl5eTh06BC8vb0LnM/vIcnNzVWXubm5QaFQ4M6dO0X2bLi6uqonmOY7fvz46x/yP44dOwYnJyd89tln6rLbt28XqHfnzh3cv38f9vb26nbkcjlcXFxgY2MDe3t73Lx5E76+vlq1T0S6wUmZRGWMr68vqlWrht69e+P333/HrVu3EBsbi/Hjx+Pu3bsAgAkTJuCLL75AdHQ0/vrrL4wePfqVe0jUrl0bfn5+CAgIQHR0tPqemzdvBgA4OTlBJpNh165dePjwIZ48eQJzc3NMnjwZgYGBiIyMxI0bN3D27FksX75cPdFx5MiRuHbtGqZMmYL4+HhERUUhIiJCq+etX78+7ty5g40bN+LGjRtYtmxZoRNMlUol/Pz8cOHCBfz+++8YP348Bg4cCFtbWwDAnDlzEBISgmXLluHq1au4ePEiwsPDsXjxYq3iIaKSYUJBVMZUqVIFhw8fhqOjI/r16wdXV1cMHz4cmZmZ6h6LSZMm4f3334efnx/c3d1hbm6Ovn37vvK+K1euxLvvvovRo0ejYcOG+PDDD5GRkQEAqFmzJubMmYNp06bBxsYGY8eOBQDMnTsXM2bMQEhICFxdXdGtWzfs3r0bzs7OAF7Ma/jpp58QHR2NZs2aYdWqVViwYIFWz/vOO+8gMDAQY8eORfPmzXHs2DHMmDGjQL169eqhX79+ePvtt9G1a1c0bdpUY1noiBEj8P333yM8PBxNmjSBp6cnIiIi1LESUemSCUXN4iIiIiIqJvZQEBERkWhMKIiIiEg0JhREREQkGhMKIiIiEo0JBREREYnGhIKIiIhEY0JBREREojGhICIiItGYUBAREZFoTCiIiIhINCYUREREJBoTCiIiIhLt/wAS+DolBFNrdAAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        NORM       1.00      0.06      0.11       116\n",
            "         MUS       0.53      0.93      0.68        76\n",
            "         STR       0.49      0.72      0.59       112\n",
            "\n",
            "    accuracy                           0.52       304\n",
            "   macro avg       0.68      0.57      0.46       304\n",
            "weighted avg       0.70      0.52      0.43       304\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Classification Report on training data\n",
        "#Load model\n",
        "model_name_to_load = 'model.pth'\n",
        "save_dir=F\"/content/drive/My Drive/Colab Notebooks/Saved models/Latest save/{model_name_to_load}\"\n",
        "\n",
        "state_dict = torch.load(save_dir)\n",
        "model.load_state_dict(state_dict)\n",
        "\n",
        "with torch.no_grad():\n",
        "  for inputs, labels in train:\n",
        "    outputs = model(inputs)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    labels_array.extend(labels.cpu().numpy())\n",
        "    predictions.extend(predicted.cpu().numpy())\n",
        "\n",
        "    #labels.extend(labels.cuda().numpy())\n",
        "    #predictions.extend(predicted.cuda().numpy())\n",
        "print(\"end\")\n",
        "#Classification report\n",
        "print(\"On Training Data\")\n",
        "print(classification_report(labels_array, predictions, target_names=['NORM', 'MUS', 'STR']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "id": "K3ms4depACjd",
        "outputId": "7b2e3d05-6a5e-46d1-db69-bfb418ff82b4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-dff5124017a2>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mlabels_array\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-2ec640917d90>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;31m# x = self.maxpool(x)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-2ec640917d90>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 460\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    454\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 456\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    457\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}