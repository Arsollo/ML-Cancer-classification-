{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jn6x-VUy2Qm",
        "outputId": "8c2e5670-ff70-430d-f854-73f73143e025"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown https://drive.google.com/drive/folders/19JWGJib5Y3PixVbsAf-EpYZZkkFvU6DC?usp=sharing"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLJWpfMZy3bI",
        "outputId": "2b8a6069-bca7-43e4-d2ed-a321b6e422bc"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gdown/parse_url.py:35: UserWarning: You specified a Google Drive link that is not the correct link to download a file. You might want to try `--fuzzy` option or the following url: https://drive.google.com/uc?id=None\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/drive/folders/19JWGJib5Y3PixVbsAf-EpYZZkkFvU6DC?usp=sharing\n",
            "To: /content/drive/My Drive/Colab Notebooks/Comp432Project/Dataset1/ColorectalCancer_/19JWGJib5Y3PixVbsAf-EpYZZkkFvU6DC?usp=sharing\n",
            "\r0.00B [00:00, ?B/s]\r1.64kB [00:00, 3.72MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir(\"/content/drive/My Drive/Colab Notebooks/Comp432Project/Dataset1/ColorectalCancer_\")"
      ],
      "metadata": {
        "id": "JzJVnF1ey7st"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#print(torch.cuda.is_available())\n",
        "\n",
        "#torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "iGY7lPxlA6N3"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_data():\n",
        "    data_dir = '/content/drive/My Drive/Colab Notebooks/Comp432Project/Dataset1/ColorectalCancer_'\n",
        "    transform = transforms.Compose([transforms.ToTensor(),transforms.Resize((64,64))])\n",
        "    data_set = datasets.ImageFolder(root=data_dir, transform=transform)\n",
        "    print(data_set.classes)\n",
        "\n",
        "    n = len(data_set)  # total number of examples\n",
        "    n_test = int(0.20 * n)  # take ~20% for test\n",
        "    for x in range(0, 9):  # rounding it to be divisible by 4\n",
        "        n_test += 1\n",
        "        if n_test % 4 == 0:\n",
        "            break\n",
        "    train_set, test_set = torch.utils.data.random_split(data_set, [n - n_test, n_test])\n",
        "\n",
        "    train = DataLoader(train_set, batch_size=32, shuffle=True)\n",
        "    test = DataLoader(test_set, batch_size=32, shuffle=False)\n",
        "\n",
        "\n",
        "    return train, test"
      ],
      "metadata": {
        "id": "JSPM_zWYBAhI"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "YAU1Kv4ExxQN"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Defining the Model\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "\n",
        "        # First convolutional layer (conv1)\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        # Second convolutional layer (conv2)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        # Shortcut connection (if needed)\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_channels != out_channels:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_channels)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        out += self.shortcut(x)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "#\n",
        "class ResNet18(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(ResNet18, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "        self.layer1 = self.make_layer(64, 64, 2, stride=1)\n",
        "        self.layer2 = self.make_layer(64, 128, 2, stride=2)\n",
        "        self.layer3 = self.make_layer(128, 256, 2, stride=2)\n",
        "        self.layer4 = self.make_layer(256, 512, 2, stride=2)\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(512, num_classes)\n",
        "\n",
        "    def make_layer(self, in_channels, out_channels, num_blocks, stride):\n",
        "        layers = []\n",
        "        layers.append(ResidualBlock(in_channels, out_channels, stride))\n",
        "        for _ in range(1, num_blocks):\n",
        "            layers.append(ResidualBlock(out_channels, out_channels, 1))\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        # x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting the data\n",
        "train, test= get_data()\n",
        "# Instanciating the ResNet18 Class created earlier and Assigning it as our model\n",
        "model = ResNet18(3)\n",
        "\n",
        "# The loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "#\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "# momentum=0.9\n",
        "\n",
        "# Using Cuda cores for the training\n",
        "#model=model.cuda()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jVXDuz1vBR5Z",
        "outputId": "6d438c34-ee11-4667-a8ce-c842a400c15b"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['MUS', 'NORM', 'STR']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training\n",
        "num_epoch=2\n",
        "lr=0.01\n",
        "batch_size = 2\n",
        "print(\"train\")\n",
        "for epoch in range(1, num_epoch):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in train:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    print(f\"Epoch {epoch+1}/{num_epoch}, Loss: {running_loss / len(train)}\")\n",
        "\n",
        "#del model\n",
        "#torch.cuda.empty_cache()\n",
        "\n",
        "print(\"end\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XDwrQFSFBX8Y",
        "outputId": "de239f1d-1832-4d48-f29a-7fd6a1488f3e"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train\n",
            "Epoch 2/2, Loss: 0.22309074364602566\n",
            "end\n"
          ]
        }
      ]
    }
  ]
}